{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb36c5e-d7df-47fa-ae4c-a67aced74eb6",
   "metadata": {},
   "source": [
    "# Using Univariate Outlier Detection Techniques to find C2 Beacons\n",
    "\n",
    "\n",
    "Over the last week or so I've been working through simple univariate anomaly detection code projects from the book 'Finding Ghosts in Your Data: Anomaly Detection Techniques with Examples in Python'. To this point the book has introduced conceptual ideas that help find outliers in datasets by using single features, hence 'univariate'. \n",
    "\n",
    "Seeing these things work with test data helps solidify the understanding of whats going on behind the scenes, but applying it to domain specific problems is the ultimate goal. A commomn usecase for outlier detection is finding interesting connections in a sea of of firewall or netflow logs that says this flow of data is unlike the others based on any number of continuous data points that typical are contained in these kind of logs. I.E. the number of flows, the number of bytes transferred between the two hosts, the intervals of connections, the duration of the connections etc.\n",
    "\n",
    "Coincidentally I recently came across a set of threat hunting/ beacon detection challenges provided by Active Counter Measures. This would be a good place to apply real world data to the outlier detection and see if it actually works.\n",
    "\n",
    "---------\n",
    "\n",
    "[**Challenge 1 - AsyncRat**](https://www.activecountermeasures.com/malware-of-the-day-asyncrat/)  \n",
    "\n",
    "Detect the presence of a C2 beacon from a 24 hour collection of Zeek logs that contain post-exploitation communication traffic. The link above describes the lab setup including the C2 address and the beacon characteristics as:\n",
    "\n",
    "- C2 Server: 172.208.51.75  \n",
    "- Beacon Timing: 6.5s  \n",
    "- Jitter: +/- 1.5s\n",
    "\n",
    "**Lets give it a go**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c490cb-cd04-4599-9a17-afa124259724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels import robust\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a9f046-803a-4430-b00c-715be742ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper dictionary to help properly assign column names based on the type of Zeek logs being analyzed\n",
    "\n",
    "zeek_cols = {'capture_loss': ['ts', 'ts_delta', 'peer', 'gaps', 'acks', 'percent_lost'],\n",
    " 'conn': ['ts', 'uid', 'orig_h', 'orig_p', 'resp_h',\n",
    "        'resp_p', 'proto', 'service', 'duration', 'orig_bytes', 'resp_bytes',\n",
    "        'conn_state', 'local_orig', 'local_resp', 'missed_bytes', 'history',\n",
    "        'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes',\n",
    "        'tunnel_parents'],\n",
    " 'dhcp': ['ts', 'uids', 'client_addr', 'server_addr', 'mac',\n",
    "        'host_name', 'client_fqdn', 'domain', 'requested_addr', 'assigned_addr',\n",
    "        'lease_time', 'client_message', 'server_message', 'msg_types',\n",
    "        'duration'],\n",
    " 'dns': ['ts', 'uid', 'id.orig_h', 'id.orig_p', 'id.resp_h',\n",
    "        'id.resp_p', 'proto', 'trans_id', 'rtt', 'query', 'qclass',\n",
    "        'qclass_name', 'qtype', 'qtype_name', 'rcode', 'rcode_name', 'AA', 'TC',\n",
    "        'RD', 'RA', 'Z', 'answers', 'TTLs', 'rejected'],\n",
    " 'files': ['ts', 'fuid', 'tx_hosts', 'rx_hosts', 'conn_uids', 'source',\n",
    "        'depth', 'analyzers', 'mime_type', 'filename', 'duration', 'local_orig',\n",
    "        'is_orig', 'seen_bytes', 'total_bytes', 'missing_bytes',\n",
    "        'overflow_bytes', 'timedout', 'parent_fuid', 'md5', 'sha1', 'sha256',\n",
    "        'extracted', 'extracted_cutoff', 'extracted_size'],\n",
    " 'http': ['ts', 'uid', 'id.orig_h', 'id.orig_p', 'id.resp_h',\n",
    "        'id.resp_p', 'trans_depth', 'method', 'host', 'uri', 'referrer',\n",
    "        'version', 'user_agent', 'origin', 'request_body_len',\n",
    "        'response_body_len', 'status_code', 'status_msg', 'info_code',\n",
    "        'info_msg', 'tags', 'username', 'password', 'proxied', 'orig_fuids',\n",
    "        'orig_filenames', 'orig_mime_types', 'resp_fuids', 'resp_filenames',\n",
    "        'resp_mime_types'],\n",
    " 'notice': ['ts', 'uid', 'id.orig_h', 'id.orig_p', 'id.resp_h',\n",
    "        'id.resp_p', 'fuid', 'file_mime_type', 'file_desc', 'proto', 'note',\n",
    "        'msg', 'sub', 'src', 'dst', 'p', 'n', 'peer_descr', 'actions',\n",
    "        'email_dest', 'suppress_for', 'remote_location.country_code',\n",
    "        'remote_location.region', 'remote_location.city',\n",
    "        'remote_location.latitude', 'remote_location.longitude'],\n",
    " 'ntp': ['ts', 'uid', 'id.orig_h', 'id.orig_p', 'id.resp_h',\n",
    "        'id.resp_p', 'version', 'mode', 'stratum', 'poll', 'precision',\n",
    "              'xmt_time', 'num_exts'],\n",
    " 'ssl': ['ts', 'uid', 'id.orig_h', 'id.orig_p', 'id.resp_h',\n",
    "        'id.resp_p', 'version', 'cipher', 'curve', 'server_name', 'resumed',\n",
    "        'last_alert', 'next_protocol', 'established', 'cert_chain_fuids',\n",
    "        'client_cert_chain_fuids', 'subject', 'issuer', 'client_subject',\n",
    "        'client_issuer', 'validation_status'],\n",
    " 'stats': ['ts', 'peer', 'mem', 'pkts_proc', 'bytes_recv',\n",
    "        'pkts_dropped', 'pkts_link', 'pkt_lag', 'events_proc', 'events_queued',\n",
    "        'active_tcp_conns', 'active_udp_conns', 'active_icmp_conns',\n",
    "        'tcp_conns', 'udp_conns', 'icmp_conns', 'timers', 'active_timers',\n",
    "        'files', 'active_files', 'dns_requests', 'active_dns_requests',\n",
    "        'reassem_tcp_size', 'reassem_file_size', 'reassem_frag_size',\n",
    "        'reassem_unknown_size'],\n",
    " 'weird': ['ts', 'uid', 'id.orig_h', 'id.orig_p', 'id.resp_h',\n",
    "        'id.resp_p', 'name', 'addl', 'notice', 'peer', 'source'],\n",
    " 'x509': ['ts', 'id', 'certificate.version', 'certificate.serial',\n",
    "        'certificate.subject', 'certificate.issuer',\n",
    "        'certificate.not_valid_before', 'certificate.not_valid_after',\n",
    "        'certificate.key_alg', 'certificate.sig_alg', 'certificate.key_type',\n",
    "        'certificate.key_length', 'certificate.exponent', 'certificate.curve',\n",
    "        'san.dns', 'san.uri', 'san.email', 'san.ip', 'basic_constraints.ca',\n",
    "        'basic_constraints.path_len']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e78457-7a9f-4b24-a100-34f8fbdc37df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the conn log file, the first 8 rows contain file metadata\n",
    "# so we skip those rows on the initial load\n",
    "\n",
    "df = pd.read_csv(\"async_infection_zeek_logs/conn.log\", sep=\"\\t\", skiprows=8, names=zeek_cols[\"conn\"], low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "848c9838-aa82-4bf7-b155-404cadb7f184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ts</th>\n",
       "      <th>uid</th>\n",
       "      <th>orig_h</th>\n",
       "      <th>orig_p</th>\n",
       "      <th>resp_h</th>\n",
       "      <th>resp_p</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>resp_bytes</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>local_orig</th>\n",
       "      <th>local_resp</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>history</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>tunnel_parents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1714219472.127111</td>\n",
       "      <td>CD2Swb3CglD8mdmAX</td>\n",
       "      <td>192.168.100.152</td>\n",
       "      <td>50110.0</td>\n",
       "      <td>204.79.197.239</td>\n",
       "      <td>443.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>RSTRH</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1714219472.978589</td>\n",
       "      <td>C3YUyT31BXg7DV30fj</td>\n",
       "      <td>192.168.100.152</td>\n",
       "      <td>50080.0</td>\n",
       "      <td>52.123.251.169</td>\n",
       "      <td>443.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>RSTRH</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1714219473.206099</td>\n",
       "      <td>CnVQMw2rQ7TU9dw92l</td>\n",
       "      <td>192.168.100.152</td>\n",
       "      <td>50102.0</td>\n",
       "      <td>204.79.197.219</td>\n",
       "      <td>443.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>RSTRH</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1714219475.003535</td>\n",
       "      <td>Co8goqBndOQb4OaDb</td>\n",
       "      <td>192.168.100.152</td>\n",
       "      <td>50096.0</td>\n",
       "      <td>204.79.197.203</td>\n",
       "      <td>443.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>RSTRH</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1714219475.469351</td>\n",
       "      <td>Ci0Z78LEBLMRD2Bvb</td>\n",
       "      <td>192.168.100.152</td>\n",
       "      <td>50091.0</td>\n",
       "      <td>204.79.197.237</td>\n",
       "      <td>443.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>RSTRH</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((35949, 21), None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking for desired schema\n",
    "df.shape, display(HTML(df.head().to_html(index=False) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f173c24-bb49-4592-8397-0c084198d761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>uid</th>\n",
       "      <th>orig_h</th>\n",
       "      <th>orig_p</th>\n",
       "      <th>resp_h</th>\n",
       "      <th>resp_p</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>...</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>local_orig</th>\n",
       "      <th>local_resp</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>history</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>tunnel_parents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35947</th>\n",
       "      <td>1714219639.151060</td>\n",
       "      <td>CM8pCB4HbWHhT7qlKc</td>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>49808.0</td>\n",
       "      <td>52.226.139.180</td>\n",
       "      <td>443.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>86160.385716</td>\n",
       "      <td>6001</td>\n",
       "      <td>...</td>\n",
       "      <td>OTH</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DaTdATT</td>\n",
       "      <td>472.0</td>\n",
       "      <td>25243.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>26700.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35948</th>\n",
       "      <td>#close</td>\n",
       "      <td>2024-05-08-19-16-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ts                  uid           orig_h   orig_p  \\\n",
       "35947  1714219639.151060   CM8pCB4HbWHhT7qlKc  192.168.100.136  49808.0   \n",
       "35948             #close  2024-05-08-19-16-08              NaN      NaN   \n",
       "\n",
       "               resp_h  resp_p proto service      duration orig_bytes  ...  \\\n",
       "35947  52.226.139.180   443.0   tcp       -  86160.385716       6001  ...   \n",
       "35948             NaN     NaN   NaN     NaN           NaN        NaN  ...   \n",
       "\n",
       "      conn_state local_orig local_resp missed_bytes  history orig_pkts  \\\n",
       "35947        OTH          -          -          0.0  DaTdATT     472.0   \n",
       "35948        NaN        NaN        NaN          NaN      NaN       NaN   \n",
       "\n",
       "       orig_ip_bytes  resp_pkts  resp_ip_bytes  tunnel_parents  \n",
       "35947        25243.0      420.0        26700.0               -  \n",
       "35948            NaN        NaN            NaN             NaN  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Zeek logs end with a close signature, which does not contain\n",
    "# useful data, we need to get rid of it\n",
    "\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61ca255-091e-4c4a-bc68-56d77cc753a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the last row using index based on slicing\n",
    "\n",
    "df = df.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f558527-d054-48b0-bd3a-7722f7ec6de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>uid</th>\n",
       "      <th>orig_h</th>\n",
       "      <th>orig_p</th>\n",
       "      <th>resp_h</th>\n",
       "      <th>resp_p</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>...</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>local_orig</th>\n",
       "      <th>local_resp</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>history</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>tunnel_parents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35946</th>\n",
       "      <td>1714219603.255488</td>\n",
       "      <td>C8bzgl4ynMAiTuzUOi</td>\n",
       "      <td>192.168.100.152</td>\n",
       "      <td>49695.0</td>\n",
       "      <td>52.226.139.185</td>\n",
       "      <td>443.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>86243.962070</td>\n",
       "      <td>5649</td>\n",
       "      <td>...</td>\n",
       "      <td>OTH</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DTadATT</td>\n",
       "      <td>471.0</td>\n",
       "      <td>24853.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>26223.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35947</th>\n",
       "      <td>1714219639.151060</td>\n",
       "      <td>CM8pCB4HbWHhT7qlKc</td>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>49808.0</td>\n",
       "      <td>52.226.139.180</td>\n",
       "      <td>443.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>86160.385716</td>\n",
       "      <td>6001</td>\n",
       "      <td>...</td>\n",
       "      <td>OTH</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DaTdATT</td>\n",
       "      <td>472.0</td>\n",
       "      <td>25243.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>26700.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ts                 uid           orig_h   orig_p  \\\n",
       "35946  1714219603.255488  C8bzgl4ynMAiTuzUOi  192.168.100.152  49695.0   \n",
       "35947  1714219639.151060  CM8pCB4HbWHhT7qlKc  192.168.100.136  49808.0   \n",
       "\n",
       "               resp_h  resp_p proto service      duration orig_bytes  ...  \\\n",
       "35946  52.226.139.185   443.0   tcp       -  86243.962070       5649  ...   \n",
       "35947  52.226.139.180   443.0   tcp       -  86160.385716       6001  ...   \n",
       "\n",
       "      conn_state local_orig local_resp missed_bytes  history orig_pkts  \\\n",
       "35946        OTH          -          -          0.0  DTadATT     471.0   \n",
       "35947        OTH          -          -          0.0  DaTdATT     472.0   \n",
       "\n",
       "       orig_ip_bytes  resp_pkts  resp_ip_bytes  tunnel_parents  \n",
       "35946        24853.0      417.0        26223.0               -  \n",
       "35947        25243.0      420.0        26700.0               -  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the last row of the dataframe is clean data\n",
    "\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5cb46c8-e06e-4176-959c-5267b348d212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Time</th>\n",
       "      <th>ts</th>\n",
       "      <th>uid</th>\n",
       "      <th>orig_h</th>\n",
       "      <th>orig_p</th>\n",
       "      <th>resp_h</th>\n",
       "      <th>resp_p</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>resp_bytes</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>local_orig</th>\n",
       "      <th>local_resp</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>history</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>tunnel_parents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2024-04-27 07:04:32.127111</td>\n",
       "      <td>1714219472.127111</td>\n",
       "      <td>CD2Swb3CglD8mdmAX</td>\n",
       "      <td>192.168.100.152</td>\n",
       "      <td>50110.0</td>\n",
       "      <td>204.79.197.239</td>\n",
       "      <td>443.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>RSTRH</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2024-04-27 07:04:32.978589</td>\n",
       "      <td>1714219472.978589</td>\n",
       "      <td>C3YUyT31BXg7DV30fj</td>\n",
       "      <td>192.168.100.152</td>\n",
       "      <td>50080.0</td>\n",
       "      <td>52.123.251.169</td>\n",
       "      <td>443.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>RSTRH</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^r</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Not necesarily needed but I like to see human read timestamps when working\n",
    "# We'll convert the timestamps to datetime objects\n",
    "# insert the objects into the first column of the dataframe\n",
    "# and give the column a name of Time \n",
    "\n",
    "converted_timestamps = [datetime.fromtimestamp(ts) for ts in df.ts.astype(float)]\n",
    "df.insert(0, \"Time\", converted_timestamps)\n",
    "display(HTML( df.head(2).to_html(index=False) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e3a9b-5134-4e95-870e-d3b74c26670f",
   "metadata": {},
   "source": [
    "#\n",
    "We have our zeek logs loaded and properly setup for analysis. Since we want to focus our analysis on communication between individual src and dest IPs we can perform some aggregation using groupby to create a dataframe of unique src, dest, dest port combinations, then using these unique values perform some summarization operations \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a4cc21d-05de-4baa-b476-65f93901f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a method to calculate the connection intervals\n",
    "# between hosts\n",
    "\n",
    "def make_time_interval(time_col):\n",
    "    \"Take a list of time columns, sort and return the intervals\"\n",
    "    time_col.sort(reverse=True)\n",
    "    intervals = []\n",
    "    for i in range(0, len(time_col)-1):\n",
    "        if i < len(time_col):\n",
    "            change = time_col[i] - time_col[i+1]\n",
    "            seconds_change = change.total_seconds()\n",
    "            intervals.append(abs(seconds_change))\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c5170e9-d8c4-4e57-b4e2-34f9afe1229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing unique source and dest pairs\n",
    "reduced = df[[\"orig_h\", \"resp_h\", \"resp_p\"]].value_counts().reset_index(name=\"pair_counts\").query(\"pair_counts > 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee1243cd-db15-4cff-9b4e-ac19de570d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>orig_h</th>\n",
       "      <th>resp_h</th>\n",
       "      <th>resp_p</th>\n",
       "      <th>pair_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>172.208.51.75</td>\n",
       "      <td>7707.0</td>\n",
       "      <td>13281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>7680.0</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(35948, 359, None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique pairs\n",
    "len(df), len(reduced), display(HTML(reduced.head(2).to_html(index=False) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e3de6e3-d821-4de3-824a-914033ba53b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform log summarization for the unique src/dest pairs \n",
    "# Aggregate log statistics, create a dictionary for\n",
    "# each pair and create a new dataframe after processing\n",
    "\n",
    "\n",
    "meta_list = []\n",
    "for pair in reduced.itertuples():\n",
    "    tmp_df = df[(df.orig_h == pair.orig_h) & (df.resp_h == pair.resp_h)]\n",
    "    times = tmp_df[\"Time\"].tolist()\n",
    "    intervals = make_time_interval(times)\n",
    "    count = len(intervals)\n",
    "    sum_bytes_in = tmp_df.resp_ip_bytes.sum()\n",
    "    sum_bytes_out = tmp_df.orig_ip_bytes.sum()\n",
    "    \n",
    "    meta = {\n",
    "        \"src\" : pair.orig_h,\n",
    "        \"dest\" : pair.resp_h,\n",
    "        \"dest_port\": pair.resp_p,\n",
    "        \"interval_average\" : np.mean(intervals),\n",
    "        \"interval_std\" : np.std(intervals),\n",
    "        \"count\" : len(intervals) + 1,\n",
    "        \"bytes_out\" : sum_bytes_out,\n",
    "        \"bytes_in\" : sum_bytes_in\n",
    "    }\n",
    "    meta_list.append(meta)\n",
    "\n",
    "new = pd.DataFrame(meta_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd00089c-b4a5-489c-9d2f-df7b95359a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional aggregate operations to transform bytes to MB \n",
    "# and calculate per session byte averages from in and out \n",
    "# perspective\n",
    "\n",
    "new[\"bytes_diff\"] = (new.bytes_out - new.bytes_in) / 1024 / 1024\n",
    "new[\"out_bytes_per_session\"] = new.bytes_out / new[\"count\"]\n",
    "new[\"in_bytes_per_session\"] = new.bytes_in / new[\"count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f237374-9bb3-48f2-a29c-6df31eeeec19",
   "metadata": {},
   "source": [
    "## Quick analysis based on the most frequently occuring connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e0e7100-f447-49e2-81f3-181f16b3b2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>src</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>interval_average</th>\n",
       "      <th>interval_std</th>\n",
       "      <th>count</th>\n",
       "      <th>bytes_out</th>\n",
       "      <th>bytes_in</th>\n",
       "      <th>bytes_diff</th>\n",
       "      <th>out_bytes_per_session</th>\n",
       "      <th>in_bytes_per_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>172.208.51.75</td>\n",
       "      <td>7707.0</td>\n",
       "      <td>6.500680</td>\n",
       "      <td>0.868396</td>\n",
       "      <td>13281</td>\n",
       "      <td>19789913.0</td>\n",
       "      <td>17996565.0</td>\n",
       "      <td>1.710270</td>\n",
       "      <td>1490.092086</td>\n",
       "      <td>1355.060989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>192.168.100.2</td>\n",
       "      <td>137.0</td>\n",
       "      <td>50.376894</td>\n",
       "      <td>45.577729</td>\n",
       "      <td>1715</td>\n",
       "      <td>754165.0</td>\n",
       "      <td>126635.0</td>\n",
       "      <td>0.598459</td>\n",
       "      <td>439.746356</td>\n",
       "      <td>73.839650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>192.168.100.2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>50.376894</td>\n",
       "      <td>45.577729</td>\n",
       "      <td>1715</td>\n",
       "      <td>754165.0</td>\n",
       "      <td>126635.0</td>\n",
       "      <td>0.598459</td>\n",
       "      <td>439.746356</td>\n",
       "      <td>73.839650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>192.168.100.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.376894</td>\n",
       "      <td>45.577729</td>\n",
       "      <td>1715</td>\n",
       "      <td>754165.0</td>\n",
       "      <td>126635.0</td>\n",
       "      <td>0.598459</td>\n",
       "      <td>439.746356</td>\n",
       "      <td>73.839650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>7680.0</td>\n",
       "      <td>74.571572</td>\n",
       "      <td>171.628866</td>\n",
       "      <td>1151</td>\n",
       "      <td>334413.0</td>\n",
       "      <td>238878.0</td>\n",
       "      <td>0.091109</td>\n",
       "      <td>290.541268</td>\n",
       "      <td>207.539531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Sort the dataframe looking at the most src/dest pairs with the most connections\n",
    "display(HTML(new.sort_values(by=\"count\", ascending=False).head().to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74870a73-f8e3-4212-94e5-2a787f094beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(15.759546965548177), np.float64(277.2234106091422))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new[\"count\"].skew(), new[\"count\"].kurtosis(), "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd408554-f9d2-4787-a30d-375cd1b72e45",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "We can see that the top src/dest pair has 13.2k sightings, well over the next most frequent connection. This by all accounts stands out as an outlier within this dataset. In addition to th extreme high frequency count, looking at the observed characteristics for this pair we see an unusual destination port (7777), a pretty short average interval (6.5). These would all lead me to dig into this set of connections a little more, maybe now is time to perform IP reputation look ups, see what the interwebs say about TCP port 7777. If available, I would pivot to a tool with endpoint visibility to see if I can find the responsible process that spawned the connection and so on.\n",
    "\n",
    "Of course we know this connection is in fact the C2 beacon. We even see the summarization methodology worked well because as the C2 configuration information described the beacon is set to run once every 6.5 seconds +/- 1.5 seconds of jitter and our summarization technique above calculates the average interval of 6.5 with a standard deviation of 0.87. \n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48361c03-90fb-4b6f-b4fc-c6afe63bde2d",
   "metadata": {},
   "source": [
    "## Bringing in the functions created during my time learning univariate anomaly detection \n",
    "The functions below can be applied to datasets to find potential anomalies in datasets based on a single feature from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01adbff1-5a7d-4ade-a345-c79af0baf00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stat(val:float,\n",
    "               midpoint:float,\n",
    "               distance:int,\n",
    "               n:int):\n",
    "    \"\"\"\n",
    "    Check if a given value is within a given range of a \n",
    "    midpoint value and a number of increments. If the value is within \n",
    "    this range return a percentage else return 1.0 indicating the value \n",
    "    is an statistical outlier\n",
    "    \"\"\"\n",
    "    if (abs(val - midpoint) < (n * distance)):\n",
    "        return abs(val-midpoint) / (n * distance)\n",
    "    return 1.0\n",
    "\n",
    "def check_sd(val:float,\n",
    "             mean:float,\n",
    "             sd:float,\n",
    "             min_num_sd:int):\n",
    "     \"\"\"\n",
    "     Check if a given value is a specified number of \n",
    "     standard deviations away from the mean\n",
    "     \"\"\"\n",
    "     return check_stat(val, mean, sd, min_num_sd)\n",
    "\n",
    "def check_mad(val:float,\n",
    "              median:float,\n",
    "              mad:float,\n",
    "              min_num_mad:int):\n",
    "    \"\"\"\n",
    "    Check if a given value is with the range of\n",
    "    the median absolute value and a specific length or distance\n",
    "    If the value is within the range return a percentage, else\n",
    "    return 1.o indicating it is an outlier\n",
    "    \"\"\"\n",
    "    return check_stat(val, median, mad, min_num_mad)\n",
    "\n",
    "def check_iqr(val:float,\n",
    "              median:float,\n",
    "              p25:float,\n",
    "              p75:float,\n",
    "              iqr:float,\n",
    "              min_iqr_diff:float):\n",
    "    \"\"\"\n",
    "    Check if on which side of the median a value exists\n",
    "    If below the median checks if the value is min_iqr_diff times below the p25 IQR\n",
    "    if above checks if the value min_iqr_diff times above the p75.\n",
    "    if the value passes those checks return 1.0 to suggest the value\n",
    "    is an outlier\n",
    "    \"\"\"\n",
    "    if val < median:\n",
    "        if val > p25:\n",
    "             return 0.0\n",
    "        elif (p25 - val) < (min_iqr_diff * iqr):\n",
    "             return abs(p25 - val) / (min_iqr_diff * iqr)\n",
    "        else:\n",
    "            return 1.0\n",
    "    else:\n",
    "        if val < p75:\n",
    "            return 0.0\n",
    "        elif (val - p75) < (min_iqr_diff * iqr):\n",
    "            return abs(val - p75) / (min_iqr_diff * iqr)\n",
    "        else:\n",
    "            return 1.0\n",
    "        \n",
    "\n",
    "def run_tests(dataframe):\n",
    "    \"\"\"\n",
    "    Pandas dataframe containing univariate data to perform \n",
    "    anomaly detection against\n",
    "    \"\"\"\n",
    "    mean = dataframe.value.mean()\n",
    "    sd = dataframe.value.std(0)\n",
    "    p25 = np.quantile(dataframe.value, 0.25)\n",
    "    p75 = np.quantile(dataframe.value, 0.75)\n",
    "    iqr = p75 - p25\n",
    "    median = dataframe.value.median()\n",
    "    mad = robust.mad(dataframe.value)\n",
    "    calculations = {\n",
    "        \"mean\": mean, \"sd\": sd, \"p25\": p25,\n",
    "        \"p75\": p75, \"iqr\": iqr, \"median\": median,\n",
    "        \"mad\":mad\n",
    "    }\n",
    "    dataframe[\"sds\"] = [check_sd(val, mean, sd, 3.0) for val in dataframe.value]\n",
    "    dataframe[\"mads\"] = [check_mad(val, median, mad, 3.0) for val in dataframe.value]\n",
    "    dataframe[\"iqrs\"] = [check_iqr(val, median, p25, p75, iqr, 1.5) for val in dataframe.value]\n",
    "    \n",
    "    return (dataframe, calculations)\n",
    "    \n",
    "def score_results(\n",
    "        dataframe,\n",
    "        weights\n",
    "):\n",
    "    \"\"\"\n",
    "    Take a dataframe and dictionary of weights\n",
    "    \"\"\"\n",
    "    return dataframe.assign(anomaly_score=(\n",
    "        dataframe[\"sds\"] * weights[\"sds\"] + \n",
    "        dataframe[\"iqrs\"] * weights[\"iqrs\"] +\n",
    "        dataframe[\"mads\"] * weights[\"mads\"]\n",
    "    ))\n",
    "\n",
    "def determine_outliers(\n",
    "        dataframe,\n",
    "        sensitivity_score,\n",
    "        max_fractional_anomalies\n",
    "):\n",
    "    sensitivity_score = (100 -  sensitivity_score) / 100.0\n",
    "    max_fractional_anomaly_score = np.quantile(dataframe.anomaly_score,\n",
    "                                           1.0 - max_fractional_anomalies)\n",
    "    if max_fractional_anomaly_score > sensitivity_score and max_fractional_anomalies < 1.0:\n",
    "        sensitivity_score = max_fractional_anomaly_score\n",
    "        \n",
    "    return dataframe.assign(\n",
    "        is_anomaly=(dataframe.anomaly_score > sensitivity_score)\n",
    "        )\n",
    "    \n",
    "\n",
    "def detect_univariate_statistical(\n",
    "        dataframe,\n",
    "        sensitivity_score,\n",
    "        max_fractional_anomalies\n",
    "):\n",
    "    weights = {\n",
    "        \"sds\": 0.25,\n",
    "        \"iqrs\": 0.35,\n",
    "        \"mads\": 0.45\n",
    "    }\n",
    "    value_counts = len(dataframe.value)\n",
    "    if value_counts < 3:\n",
    "        return (dataframe.assign(is_anomaly=False, anomaly_score=0.0), weights, \"Must have minimum of 3 items for anomaly detection\")\n",
    "    elif (max_fractional_anomalies <= 0.0 or max_fractional_anomalies > 1.0):\n",
    "        return (dataframe.assign(is_anomaly=False, anomaly_score=0.0), weights, \"Must have valid max fraction of anomalies, 0 < x <= 1.0\")\n",
    "    elif (sensitivity_score <= 0 or sensitivity_score > 100):\n",
    "        return (dataframe.assign(is_anomaly=False, anomaly_score=0.0), weights, \"Must have valid sensitivity score, 0 < x <= 100.0\")\n",
    "    else:\n",
    "        df_test, calculations = run_tests(dataframe)\n",
    "        df_scored = score_results(df_test, weights)\n",
    "        df_out = determine_outliers(df_scored, sensitivity_score, max_fractional_anomalies)\n",
    "        return  (df_out, weights, {\"message\" : \"Ensemble of [mean +/- 3*SD, median +/- 3*MAD, median +/- 1.5*IQR],\",\n",
    "                                \"calculations\": calculations}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1b9157-764c-4bf0-8df2-21c3e0e0b1da",
   "metadata": {},
   "source": [
    "## Perform univariate anomaly detection from the dataset based on the number of sessions per src/dest pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de083617-4bfa-4fe2-b491-62b6f707ed9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Ensemble of [mean +/- 3*SD, median +/- 3*MAD, median +/- 1.5*IQR],',\n",
       " 'calculations': {'mean': np.float64(153.68802228412255),\n",
       "  'sd': np.float64(740.8499065008234),\n",
       "  'p25': np.float64(2.0),\n",
       "  'p75': np.float64(109.0),\n",
       "  'iqr': np.float64(107.0),\n",
       "  'median': np.float64(5.0),\n",
       "  'mad': np.float64(4.447806655516806)}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass the new dataframe to the  detect_univariate_statistical function, the function expects a column named \"value\"\n",
    "# to perform its tests on so we'll rename the \"count\" prior\n",
    "# to passing the dataframe. Additinally parameters to the function \n",
    "# include a sensitivitiy score which we are passing 80 which means\n",
    "# we want the function to return values that have an 80% confidence level\n",
    "# lastly minimum fraction anomaly value, which tells the function\n",
    "# that we expect atleast that fraction of the entire dataset to \n",
    "# be an outlier we are passing an initial value of 0.05\n",
    "\n",
    "res_df, _, calculations = detect_univariate_statistical(new.rename(columns={\"count\":\"value\"}), 80, .05)\n",
    "calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894ccd1b-0b0d-427a-ac27-02b0609c8f97",
   "metadata": {},
   "source": [
    "## Review the results from the above function, filter for only the records that were found as anomaly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff3eb46e-ec06-4001-ac33-8826a89a6606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>src</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>interval_average</th>\n",
       "      <th>interval_std</th>\n",
       "      <th>value</th>\n",
       "      <th>bytes_out</th>\n",
       "      <th>bytes_in</th>\n",
       "      <th>bytes_diff</th>\n",
       "      <th>out_bytes_per_session</th>\n",
       "      <th>in_bytes_per_session</th>\n",
       "      <th>sds</th>\n",
       "      <th>mads</th>\n",
       "      <th>iqrs</th>\n",
       "      <th>anomaly_score</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>172.208.51.75</td>\n",
       "      <td>7707.0</td>\n",
       "      <td>6.500680</td>\n",
       "      <td>0.868396</td>\n",
       "      <td>13281</td>\n",
       "      <td>19789913.0</td>\n",
       "      <td>17996565.0</td>\n",
       "      <td>1.710270</td>\n",
       "      <td>1490.092086</td>\n",
       "      <td>1355.060989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>7680.0</td>\n",
       "      <td>74.571572</td>\n",
       "      <td>171.628866</td>\n",
       "      <td>1151</td>\n",
       "      <td>334413.0</td>\n",
       "      <td>238878.0</td>\n",
       "      <td>0.091109</td>\n",
       "      <td>290.541268</td>\n",
       "      <td>207.539531</td>\n",
       "      <td>0.448724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.912181</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.152</td>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>7680.0</td>\n",
       "      <td>87.350425</td>\n",
       "      <td>198.150119</td>\n",
       "      <td>981</td>\n",
       "      <td>289377.0</td>\n",
       "      <td>222126.0</td>\n",
       "      <td>0.064136</td>\n",
       "      <td>294.981651</td>\n",
       "      <td>226.428135</td>\n",
       "      <td>0.372236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893059</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>192.168.100.2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>50.376894</td>\n",
       "      <td>45.577729</td>\n",
       "      <td>1715</td>\n",
       "      <td>754165.0</td>\n",
       "      <td>126635.0</td>\n",
       "      <td>0.598459</td>\n",
       "      <td>439.746356</td>\n",
       "      <td>73.839650</td>\n",
       "      <td>0.702487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975622</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>192.168.100.2</td>\n",
       "      <td>137.0</td>\n",
       "      <td>50.376894</td>\n",
       "      <td>45.577729</td>\n",
       "      <td>1715</td>\n",
       "      <td>754165.0</td>\n",
       "      <td>126635.0</td>\n",
       "      <td>0.598459</td>\n",
       "      <td>439.746356</td>\n",
       "      <td>73.839650</td>\n",
       "      <td>0.702487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975622</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>192.168.100.2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>94.935585</td>\n",
       "      <td>135.895400</td>\n",
       "      <td>911</td>\n",
       "      <td>86853.0</td>\n",
       "      <td>118550.0</td>\n",
       "      <td>-0.030229</td>\n",
       "      <td>95.338090</td>\n",
       "      <td>130.131723</td>\n",
       "      <td>0.340740</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885185</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.152</td>\n",
       "      <td>192.168.100.2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>95.458832</td>\n",
       "      <td>137.361951</td>\n",
       "      <td>905</td>\n",
       "      <td>89231.0</td>\n",
       "      <td>120438.0</td>\n",
       "      <td>-0.029761</td>\n",
       "      <td>98.597790</td>\n",
       "      <td>133.080663</td>\n",
       "      <td>0.338041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.884510</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.151</td>\n",
       "      <td>192.168.100.2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>97.536194</td>\n",
       "      <td>141.390069</td>\n",
       "      <td>884</td>\n",
       "      <td>85758.0</td>\n",
       "      <td>115894.0</td>\n",
       "      <td>-0.028740</td>\n",
       "      <td>97.011312</td>\n",
       "      <td>131.101810</td>\n",
       "      <td>0.328592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882148</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>192.168.100.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.935585</td>\n",
       "      <td>135.895400</td>\n",
       "      <td>911</td>\n",
       "      <td>86853.0</td>\n",
       "      <td>118550.0</td>\n",
       "      <td>-0.030229</td>\n",
       "      <td>95.338090</td>\n",
       "      <td>130.131723</td>\n",
       "      <td>0.340740</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885185</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.152</td>\n",
       "      <td>192.168.100.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.458832</td>\n",
       "      <td>137.361951</td>\n",
       "      <td>905</td>\n",
       "      <td>89231.0</td>\n",
       "      <td>120438.0</td>\n",
       "      <td>-0.029761</td>\n",
       "      <td>98.597790</td>\n",
       "      <td>133.080663</td>\n",
       "      <td>0.338041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.884510</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>192.168.100.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.376894</td>\n",
       "      <td>45.577729</td>\n",
       "      <td>1715</td>\n",
       "      <td>754165.0</td>\n",
       "      <td>126635.0</td>\n",
       "      <td>0.598459</td>\n",
       "      <td>439.746356</td>\n",
       "      <td>73.839650</td>\n",
       "      <td>0.702487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975622</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.151</td>\n",
       "      <td>192.168.100.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>97.536194</td>\n",
       "      <td>141.390069</td>\n",
       "      <td>884</td>\n",
       "      <td>85758.0</td>\n",
       "      <td>115894.0</td>\n",
       "      <td>-0.028740</td>\n",
       "      <td>97.011312</td>\n",
       "      <td>131.101810</td>\n",
       "      <td>0.328592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882148</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>5355.0</td>\n",
       "      <td>74.571572</td>\n",
       "      <td>171.628866</td>\n",
       "      <td>1151</td>\n",
       "      <td>334413.0</td>\n",
       "      <td>238878.0</td>\n",
       "      <td>0.091109</td>\n",
       "      <td>290.541268</td>\n",
       "      <td>207.539531</td>\n",
       "      <td>0.448724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.912181</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.152</td>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>5355.0</td>\n",
       "      <td>87.350425</td>\n",
       "      <td>198.150119</td>\n",
       "      <td>981</td>\n",
       "      <td>289377.0</td>\n",
       "      <td>222126.0</td>\n",
       "      <td>0.064136</td>\n",
       "      <td>294.981651</td>\n",
       "      <td>226.428135</td>\n",
       "      <td>0.372236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893059</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.571572</td>\n",
       "      <td>171.628866</td>\n",
       "      <td>1151</td>\n",
       "      <td>334413.0</td>\n",
       "      <td>238878.0</td>\n",
       "      <td>0.091109</td>\n",
       "      <td>290.541268</td>\n",
       "      <td>207.539531</td>\n",
       "      <td>0.448724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.912181</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.152</td>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>3.0</td>\n",
       "      <td>87.350425</td>\n",
       "      <td>198.150119</td>\n",
       "      <td>981</td>\n",
       "      <td>289377.0</td>\n",
       "      <td>222126.0</td>\n",
       "      <td>0.064136</td>\n",
       "      <td>294.981651</td>\n",
       "      <td>226.428135</td>\n",
       "      <td>0.372236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893059</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((16, 16), None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show function output\n",
    "res_df[res_df.is_anomaly == True].shape, display(HTML(res_df[res_df.is_anomaly == True].to_html(index=False) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a52000-1ee4-45b8-818e-f5f9de33048d",
   "metadata": {},
   "source": [
    "## What do the results say\n",
    "\n",
    "Interesting observation from the results. The function correctly identified the outbound connection to 172.208.51.75 as \n",
    "a potential anomaly as well as several other src/dest pairs. But just looking at the meta data for the pairs it looks like the confirmed malicious pair stands out from other pairs from the perspective of other features as well; the interval average is significant shorter and the bytes calculations are higher than most if not all.\n",
    "\n",
    "I got the idea of filtering the first round of anomalies through the detecton_univariate_statistical function, passing the results from the prior test to the function but focus on a different feature. Of course this is technically no longer univariate, but we're going with the flow here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "864be761-41ea-4cdb-a38a-f1e634a61276",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new dataframe from the first anomaly check for all pairs that were found as potential anomalies\n",
    "# Since the function is looking for a column name of value we'll rename the value column back to the original \n",
    "# name of count\n",
    "first_anomalies = res_df[res_df.is_anomaly == True].rename(columns={\"value\": \"count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "376bff97-bc24-4bf4-9a11-d1a2c0956206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>src</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>interval_average</th>\n",
       "      <th>interval_std</th>\n",
       "      <th>count</th>\n",
       "      <th>value</th>\n",
       "      <th>bytes_in</th>\n",
       "      <th>bytes_diff</th>\n",
       "      <th>out_bytes_per_session</th>\n",
       "      <th>in_bytes_per_session</th>\n",
       "      <th>sds</th>\n",
       "      <th>mads</th>\n",
       "      <th>iqrs</th>\n",
       "      <th>anomaly_score</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>172.208.51.75</td>\n",
       "      <td>7707.0</td>\n",
       "      <td>6.50068</td>\n",
       "      <td>0.868396</td>\n",
       "      <td>13281</td>\n",
       "      <td>19789913.0</td>\n",
       "      <td>17996565.0</td>\n",
       "      <td>1.71027</td>\n",
       "      <td>1490.092086</td>\n",
       "      <td>1355.060989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Rerun the detect_univariate_statistical function with the new\n",
    "# First since we're create multiple dataframes I'm going to make a new dataframe to pass to the function with a \n",
    "# more identifiable name\n",
    "\n",
    "bytes_out_df = first_anomalies.rename(columns={\"bytes_out\":\"value\"})\n",
    "\n",
    "res_df, _, calulations = detect_univariate_statistical(\n",
    "    bytes_out_df,\n",
    "    80, .05)\n",
    "calulations\n",
    "display(HTML(res_df[res_df.is_anomaly == True].to_html(index=False) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facf4128-4342-4008-9bc6-078e09e6140f",
   "metadata": {},
   "source": [
    "## And then there was one\n",
    "\n",
    "After the first round of filtering we are left with only the known C2 beacon. Lets repeat again with another feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6560f26-3175-466c-9509-da5c359fc86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>src</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>interval_average</th>\n",
       "      <th>interval_std</th>\n",
       "      <th>count</th>\n",
       "      <th>bytes_out</th>\n",
       "      <th>value</th>\n",
       "      <th>bytes_diff</th>\n",
       "      <th>out_bytes_per_session</th>\n",
       "      <th>in_bytes_per_session</th>\n",
       "      <th>sds</th>\n",
       "      <th>mads</th>\n",
       "      <th>iqrs</th>\n",
       "      <th>anomaly_score</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>172.208.51.75</td>\n",
       "      <td>7707.0</td>\n",
       "      <td>6.50068</td>\n",
       "      <td>0.868396</td>\n",
       "      <td>13281</td>\n",
       "      <td>19789913.0</td>\n",
       "      <td>17996565.0</td>\n",
       "      <td>1.71027</td>\n",
       "      <td>1490.092086</td>\n",
       "      <td>1355.060989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Another pass using a different feature\n",
    "# this time, the bytes_in metric\n",
    "\n",
    "\n",
    "bytes_in_df = first_anomalies.rename(columns={\"bytes_in\":\"value\"})\n",
    "\n",
    "res_df, _, calulations = detect_univariate_statistical(\n",
    "    bytes_in_df,\n",
    "    80, .05)\n",
    "calulations\n",
    "display(HTML(res_df[res_df.is_anomaly == True].to_html(index=False) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9ff752-65c9-4294-b0a6-8f9ec21af33d",
   "metadata": {},
   "source": [
    "## Pretty cool to cull the results in such a way that only the C2 beacon remains based on those features. \n",
    "\n",
    "It would be pretty trivial to see what the results would be for all of the aggregated features at once, we can loop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59ca0bf3-505a-411a-8420-0ecfa37c4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we'll throw the features of interest in a list\n",
    "\n",
    "feature_names = ['interval_average','interval_std','count','bytes_out','bytes_in','bytes_diff','out_bytes_per_session','in_bytes_per_session']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b020dd5-6f2d-448f-b65c-e8d3a2960cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Original Size': '35948', 'Aggregated Size': '359', 'First Reduce Size': '16'} \n",
      "\n",
      "{'Feature': 'interval_average', 'Number_Anomalous': '1'}\n",
      "{'Feature': 'interval_std', 'Number_Anomalous': '1'}\n",
      "{'Feature': 'count', 'Number_Anomalous': '1'}\n",
      "{'Feature': 'bytes_out', 'Number_Anomalous': '1'}\n",
      "{'Feature': 'bytes_in', 'Number_Anomalous': '1'}\n",
      "{'Feature': 'bytes_diff', 'Number_Anomalous': '1'}\n",
      "{'Feature': 'out_bytes_per_session', 'Number_Anomalous': '1'}\n",
      "{'Feature': 'in_bytes_per_session', 'Number_Anomalous': '1'}\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Just structure a loop block to setup the univariate AD function for each feature, outside of  the loop we'll\n",
    "# grab the initial size information and create a dictionary to store individual results as we may want to do \n",
    "# additional comparison checking pending the results of the individual tests. \n",
    "# We also print the results of each test\n",
    "\n",
    "all_findings = {}\n",
    "\n",
    "\n",
    "file_meta = {\n",
    "    \"Original Size\" : f\"{len(df)}\",\n",
    "    \"Aggregated Size\" : f\"{len(new)}\",\n",
    "    \"First Reduce Size\" : f\"{len(first_anomalies)}\"\n",
    "}\n",
    "\n",
    "print(file_meta,\"\\n\")\n",
    "for feature in feature_names:\n",
    "    \n",
    "    res_df, _, calulations = detect_univariate_statistical(first_anomalies.rename(columns={feature:\"value\"})\n",
    "                                                           ,80, .05)\n",
    "    findings_df = res_df[res_df.is_anomaly == True].loc[::]\n",
    "    results_len = len(findings_df)\n",
    "    info = {'Feature': f\"{feature}\",\n",
    "             'Number_Anomalous': f\"{results_len}\"}\n",
    "    \n",
    "    all_findings[feature] = findings_df\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2739ff9b-5e5a-487f-b6af-1adfcf3afcc3",
   "metadata": {},
   "source": [
    "# Interpreting the final output\n",
    "\n",
    "The individual results don't illuminate any new records of interest, but the reduction numbers are encouraging. As analysts who are tasked with finding the 4 inch strand of hay that is frayed on one end in a warehouse of hay, meaningful data reduction is a significant battle. We can apply manual efforts rooted in domain and environment knowledge, that'll always be needed. But there have been countless times when I have been brought into an investigation where the environment is unknown, there is no documentation and domain knowledge is nill. In those instances having a proven technique to establish a starting point from leads is huge. \n",
    "\n",
    "Even from the initial reduction we now have a dataset that we can apply meaningful enrichment to at least paint some context around the network connections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2c6ca-bd9b-46b7-ab45-e5bdf63b4566",
   "metadata": {},
   "source": [
    "#### This is works well for this particular data sample, I wonder if it works with other log samples. Luckily the good people at [active countermeasure](https://www.activecountermeasures.com/) are doing God's work and providing learners with LARGE traffic samples that contain malware communication traffic, so let's try to apply one such [sample](https://acm-motd.s3.amazonaws.com/xenorat_zeek_logs.zip) surrounding xenorat network traffic.\n",
    "\n",
    "[**Challenge 2 - Xenorat**](https://www.activecountermeasures.com/malware-of-the-day-xenorat/) \n",
    "\n",
    "- C2 Server: 172.208.51.75\n",
    "- Beacon Timing: none\n",
    "- Jitter: none\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23705a99-27a5-40a4-8924-a8342255dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The files have been saved individually going to do some globbing and pandas work to consolidate them\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb45d7ce-331e-47aa-85c0-f09c31c30963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xenorat_zeek_logs/conn.08_00_00-09_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.19_00_00-20_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.10_00_00-11_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.14_00_00-15_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.17_00_00-18_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.15_00_00-16_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.11_00_00-12_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.12_00_00-13_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.16_00_00-17_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.03_00_00-04_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.01_00_00-02_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.05_00_00-06_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.07_00_00-08_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.18_00_00-19_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.04_00_00-05_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.22_00_00-23_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.00_00_00-01_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.13_00_00-14_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.21_00_00-22_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.23_00_00-00_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.06_00_00-07_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.20_00_00-21_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.02_00_00-03_00_00.log',\n",
       " 'xenorat_zeek_logs/conn.09_00_00-10_00_00.log']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting paths to all of the conn files\n",
    "conn_files = glob.glob(\"xeno*/conn.*.log*\")\n",
    "conn_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5900427d-1b2f-4cf0-ad97-32721709263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a loop to read make each file a dataframe and store is a list\n",
    "dataframes = []\n",
    "for file in conn_files:\n",
    "    df = pd.read_csv(file, sep=\"\\t\", skiprows=8, names=zeek_cols[\"conn\"], low_memory=False)\n",
    "    # drop last row\n",
    "    df = df.iloc[:-1]\n",
    "    dataframes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69427a0d-a6c1-4dea-bb20-2bd2ddfbf937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge or concat all dataframes into one\n",
    "df = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccfe3542-e914-4e5e-8b39-762cff91da13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ts</th>\n",
       "      <th>uid</th>\n",
       "      <th>orig_h</th>\n",
       "      <th>orig_p</th>\n",
       "      <th>resp_h</th>\n",
       "      <th>resp_p</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>resp_bytes</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>local_orig</th>\n",
       "      <th>local_resp</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>history</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>tunnel_parents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1716328590.010444</td>\n",
       "      <td>CLJUG54YcbajQ03TBh</td>\n",
       "      <td>fe80::6a6f:2ae7:422e:b6d3</td>\n",
       "      <td>5353.0</td>\n",
       "      <td>ff02::fb</td>\n",
       "      <td>5353.0</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>S0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1716353683.322302</td>\n",
       "      <td>CtOxNz3ORqqZGmxCRg</td>\n",
       "      <td>192.168.2.19</td>\n",
       "      <td>35203.0</td>\n",
       "      <td>192.168.2.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>92</td>\n",
       "      <td>46</td>\n",
       "      <td>SF</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dd</td>\n",
       "      <td>2.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1716339799.016182</td>\n",
       "      <td>CoFRCu271ZoOVZedK9</td>\n",
       "      <td>192.168.2.19</td>\n",
       "      <td>58181.0</td>\n",
       "      <td>192.168.2.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>116</td>\n",
       "      <td>314</td>\n",
       "      <td>SF</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dd</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1716337592.143284</td>\n",
       "      <td>Cd0Lpp29akWmFnBeb5</td>\n",
       "      <td>192.168.2.19</td>\n",
       "      <td>33460.0</td>\n",
       "      <td>1.1.1.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>116</td>\n",
       "      <td>250</td>\n",
       "      <td>SF</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dd</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1716345387.789510</td>\n",
       "      <td>CqlKRi3h4b11GWYRi1</td>\n",
       "      <td>192.168.2.84</td>\n",
       "      <td>51306.0</td>\n",
       "      <td>23.208.15.98</td>\n",
       "      <td>443.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ssl</td>\n",
       "      <td>60.179695</td>\n",
       "      <td>2755</td>\n",
       "      <td>5796</td>\n",
       "      <td>RSTO</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ShADadR</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3287.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6288.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((44010, 21), None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out file dataframe size and preview\n",
    "df.shape, display(HTML( df.sample(5).to_html(index=False) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490fdea-64e2-4dad-bd96-0964879dead4",
   "metadata": {},
   "source": [
    "### Just copying from the code cells above and repeating the same battery of tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00bfcfa6-0808-4be1-8735-a9b2e91021fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_timestamps = [datetime.fromtimestamp(ts) for ts in df.ts.astype(float)]\n",
    "df.insert(0, \"Time\", converted_timestamps)\n",
    "reduced = df[[\"orig_h\", \"resp_h\", \"resp_p\"]].value_counts().reset_index(name=\"pair_counts\").query(\"pair_counts > 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77bb85cb-02df-404d-991d-5a2f49698921",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_list = []\n",
    "for pair in reduced.itertuples():\n",
    "    tmp_df = df[(df.orig_h == pair.orig_h) & (df.resp_h == pair.resp_h)]\n",
    "    times = tmp_df[\"Time\"].tolist()\n",
    "    intervals = make_time_interval(times)\n",
    "    count = len(intervals)\n",
    "    sum_bytes_in = tmp_df.resp_ip_bytes.sum()\n",
    "    sum_bytes_out = tmp_df.orig_ip_bytes.sum()\n",
    "    \n",
    "    meta = {\n",
    "        \"src\" : pair.orig_h,\n",
    "        \"dest\" : pair.resp_h,\n",
    "        \"dest_port\": pair.resp_p,\n",
    "        \"interval_average\" : np.mean(intervals),\n",
    "        \"interval_std\" : np.std(intervals),\n",
    "        \"count\" : len(intervals) + 1,\n",
    "        \"bytes_out\" : sum_bytes_out,\n",
    "        \"bytes_in\" : sum_bytes_in\n",
    "    }\n",
    "    meta_list.append(meta)\n",
    "\n",
    "new = pd.DataFrame(meta_list)\n",
    "\n",
    "new[\"bytes_diff\"] = (new.bytes_out - new.bytes_in) / 1024 /1024\n",
    "new[\"out_bytes_per_session\"] = new.bytes_out / new[\"count\"]\n",
    "new[\"in_bytes_per_session\"] = new.bytes_in / new[\"count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a64546c-b93d-435f-9e9e-1cc7fd455a2b",
   "metadata": {},
   "source": [
    "###\n",
    "**Spoiler:** when using the same max fraction anomaly value as the first sample. The \"outlier funnel\" failed to produce the desired results i.e the C2 traffic missed the cut. I played around with the input values and increasing the value to .10 produced meaningful results. Increasing the value is acceptable, in the end we'll have more data marked as potential outliers but still be in a better spot than not pushing the data through the funnel.\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd90b7f3-4c34-4250-ae29-b4450a2b6533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(21.287616059512075), np.float64(528.6638182201758))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting skewness and kurtosis scores for curiousity sake.\n",
    "# I'm thinking the reason we had to increase the max_number_of_anomalies variable\n",
    "# of the test has to do with the fact this sample has more skewness and kurtosis\n",
    "# which I believe means a lot of the data exists in the tail of the distibution\n",
    "# and is prone to more outliers and extreme conditions. Could be way off base\n",
    "# but wanted to capture the notes to come back to later\n",
    "\n",
    "new[\"count\"].skew(), new[\"count\"].kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e09d63d-dc12-4203-9095-af8df03f4f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>src</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>interval_average</th>\n",
       "      <th>interval_std</th>\n",
       "      <th>value</th>\n",
       "      <th>bytes_out</th>\n",
       "      <th>bytes_in</th>\n",
       "      <th>bytes_diff</th>\n",
       "      <th>out_bytes_per_session</th>\n",
       "      <th>in_bytes_per_session</th>\n",
       "      <th>sds</th>\n",
       "      <th>mads</th>\n",
       "      <th>iqrs</th>\n",
       "      <th>anomaly_score</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>192.168.2.89</td>\n",
       "      <td>52.113.194.132</td>\n",
       "      <td>443.0</td>\n",
       "      <td>4910.523579</td>\n",
       "      <td>4613.514658</td>\n",
       "      <td>16</td>\n",
       "      <td>21357.0</td>\n",
       "      <td>124598.0</td>\n",
       "      <td>-0.098458</td>\n",
       "      <td>1334.812500</td>\n",
       "      <td>7787.375000</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.807937</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.77</td>\n",
       "      <td>52.137.102.105</td>\n",
       "      <td>443.0</td>\n",
       "      <td>5595.313504</td>\n",
       "      <td>4094.807482</td>\n",
       "      <td>15</td>\n",
       "      <td>26082.0</td>\n",
       "      <td>49424.0</td>\n",
       "      <td>-0.022261</td>\n",
       "      <td>1738.800000</td>\n",
       "      <td>3294.933333</td>\n",
       "      <td>0.032479</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.808120</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.65</td>\n",
       "      <td>192.168.2.255</td>\n",
       "      <td>137.0</td>\n",
       "      <td>713.872130</td>\n",
       "      <td>483.426616</td>\n",
       "      <td>120</td>\n",
       "      <td>46636.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044476</td>\n",
       "      <td>388.633333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.811100</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.14</td>\n",
       "      <td>192.168.2.79</td>\n",
       "      <td>7680.0</td>\n",
       "      <td>104.060120</td>\n",
       "      <td>1987.751005</td>\n",
       "      <td>831</td>\n",
       "      <td>269616.0</td>\n",
       "      <td>207012.0</td>\n",
       "      <td>0.059704</td>\n",
       "      <td>324.447653</td>\n",
       "      <td>249.111913</td>\n",
       "      <td>0.564980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941245</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.82</td>\n",
       "      <td>192.168.2.1</td>\n",
       "      <td>49152.0</td>\n",
       "      <td>86.568360</td>\n",
       "      <td>134.269660</td>\n",
       "      <td>994</td>\n",
       "      <td>70694.0</td>\n",
       "      <td>183884.0</td>\n",
       "      <td>-0.107946</td>\n",
       "      <td>71.120724</td>\n",
       "      <td>184.993964</td>\n",
       "      <td>0.684326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971081</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_df, _, calculations = detect_univariate_statistical(new.rename(columns={\"count\":\"value\"}), 90, .10)\n",
    "display(HTML(res_df[res_df.is_anomaly == True].sample(5).to_html(index=False) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcca6a1a-483f-4d9a-ba12-e349f673d39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Original Size': '44010', 'Aggregated Size': '853', 'First Reduce Size': '84'} \n",
      "\n",
      "{'Feature': 'interval_average', 'Number_Anomalous': '5'}\n",
      "{'Feature': 'interval_std', 'Number_Anomalous': '5'}\n",
      "{'Feature': 'count', 'Number_Anomalous': '5'}\n",
      "{'Feature': 'bytes_out', 'Number_Anomalous': '5'}\n",
      "{'Feature': 'bytes_in', 'Number_Anomalous': '5'}\n",
      "{'Feature': 'bytes_diff', 'Number_Anomalous': '5'}\n",
      "{'Feature': 'out_bytes_per_session', 'Number_Anomalous': '5'}\n",
      "{'Feature': 'in_bytes_per_session', 'Number_Anomalous': '5'}\n"
     ]
    }
   ],
   "source": [
    "first_anomalies = res_df[res_df.is_anomaly == True].rename(columns={\"value\": \"count\"})\n",
    "feature_names = ['interval_average','interval_std','count','bytes_out','bytes_in','bytes_diff','out_bytes_per_session','in_bytes_per_session']\n",
    "all_findings = {}\n",
    "\n",
    "\n",
    "file_meta = {\n",
    "    \"Original Size\" : f\"{len(df)}\",\n",
    "    \"Aggregated Size\" : f\"{len(new)}\",\n",
    "    \"First Reduce Size\" : f\"{len(first_anomalies)}\"\n",
    "}\n",
    "\n",
    "print(file_meta,\"\\n\")\n",
    "for feature in feature_names:\n",
    "    \n",
    "    res_df, _, calulations = detect_univariate_statistical(first_anomalies.rename(columns={feature:\"value\"})\n",
    "                                                           ,60, .05)\n",
    "    findings_df = res_df[res_df.is_anomaly == True].loc[::]\n",
    "    results_len = len(findings_df)\n",
    "    info = {'Feature': f\"{feature}\",\n",
    "             'Number_Anomalous': f\"{results_len}\"}\n",
    "    \n",
    "    all_findings[feature] = findings_df\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e80bf-5d02-4714-a168-195cf0d41ac8",
   "metadata": {},
   "source": [
    "## Since we have multiple results lets bring them back together and look at as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d7cf288-7f55-4403-9252-66de18021ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>src</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>interval_average</th>\n",
       "      <th>interval_std</th>\n",
       "      <th>count</th>\n",
       "      <th>bytes_out</th>\n",
       "      <th>bytes_in</th>\n",
       "      <th>bytes_diff</th>\n",
       "      <th>out_bytes_per_session</th>\n",
       "      <th>in_bytes_per_session</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>192.168.2.82</td>\n",
       "      <td>151.101.138.172</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5782.400954</td>\n",
       "      <td>4062.185907</td>\n",
       "      <td>14</td>\n",
       "      <td>62892.0</td>\n",
       "      <td>1236375.0</td>\n",
       "      <td>-1.119121</td>\n",
       "      <td>4492.285714</td>\n",
       "      <td>8.831250e+04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td>255.255.255.255</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6930.646651</td>\n",
       "      <td>5816.460391</td>\n",
       "      <td>12</td>\n",
       "      <td>8696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>724.666667</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.15</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>6318.089140</td>\n",
       "      <td>19014.643362</td>\n",
       "      <td>12</td>\n",
       "      <td>12828.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012234</td>\n",
       "      <td>1069.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.82</td>\n",
       "      <td>52.113.195.132</td>\n",
       "      <td>443.0</td>\n",
       "      <td>6032.743888</td>\n",
       "      <td>16493.810552</td>\n",
       "      <td>12</td>\n",
       "      <td>19650.0</td>\n",
       "      <td>83327.0</td>\n",
       "      <td>-0.060727</td>\n",
       "      <td>1637.500000</td>\n",
       "      <td>6.943917e+03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.1</td>\n",
       "      <td>192.168.2.79</td>\n",
       "      <td>57935.0</td>\n",
       "      <td>6167.458337</td>\n",
       "      <td>16258.724895</td>\n",
       "      <td>12</td>\n",
       "      <td>6480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.13</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>5325.092020</td>\n",
       "      <td>16827.149606</td>\n",
       "      <td>12</td>\n",
       "      <td>63339.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060405</td>\n",
       "      <td>5278.250000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.13</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>5325.092020</td>\n",
       "      <td>16827.149606</td>\n",
       "      <td>12</td>\n",
       "      <td>63339.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060405</td>\n",
       "      <td>5278.250000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.19</td>\n",
       "      <td>1.1.1.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>7.316422</td>\n",
       "      <td>7.424754</td>\n",
       "      <td>11808</td>\n",
       "      <td>2030976.0</td>\n",
       "      <td>4132800.0</td>\n",
       "      <td>-2.004456</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>3.500000e+02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.19</td>\n",
       "      <td>192.168.2.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>22.644662</td>\n",
       "      <td>49.560266</td>\n",
       "      <td>3812</td>\n",
       "      <td>595904.0</td>\n",
       "      <td>554997.0</td>\n",
       "      <td>0.039012</td>\n",
       "      <td>156.323190</td>\n",
       "      <td>1.455921e+02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.1</td>\n",
       "      <td>224.0.0.251</td>\n",
       "      <td>5353.0</td>\n",
       "      <td>30.002055</td>\n",
       "      <td>0.042252</td>\n",
       "      <td>2880</td>\n",
       "      <td>302400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288391</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.79</td>\n",
       "      <td>192.168.2.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>81.258576</td>\n",
       "      <td>139.847327</td>\n",
       "      <td>1063</td>\n",
       "      <td>176265.0</td>\n",
       "      <td>275419.0</td>\n",
       "      <td>-0.094561</td>\n",
       "      <td>165.818438</td>\n",
       "      <td>2.590960e+02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.79</td>\n",
       "      <td>192.168.2.1</td>\n",
       "      <td>49152.0</td>\n",
       "      <td>81.258576</td>\n",
       "      <td>139.847327</td>\n",
       "      <td>1063</td>\n",
       "      <td>176265.0</td>\n",
       "      <td>275419.0</td>\n",
       "      <td>-0.094561</td>\n",
       "      <td>165.818438</td>\n",
       "      <td>2.590960e+02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.77</td>\n",
       "      <td>172.208.51.75</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>71.471786</td>\n",
       "      <td>629.141605</td>\n",
       "      <td>227</td>\n",
       "      <td>1420856.0</td>\n",
       "      <td>2043880.0</td>\n",
       "      <td>-0.594162</td>\n",
       "      <td>6259.277533</td>\n",
       "      <td>9.003877e+03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.65</td>\n",
       "      <td>224.0.0.251</td>\n",
       "      <td>5353.0</td>\n",
       "      <td>496.547620</td>\n",
       "      <td>448.979300</td>\n",
       "      <td>174</td>\n",
       "      <td>982724.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937199</td>\n",
       "      <td>5647.839080</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.19</td>\n",
       "      <td>149.112.122.10</td>\n",
       "      <td>443.0</td>\n",
       "      <td>502.592023</td>\n",
       "      <td>342.867823</td>\n",
       "      <td>172</td>\n",
       "      <td>1381676.0</td>\n",
       "      <td>443953.0</td>\n",
       "      <td>0.894282</td>\n",
       "      <td>8033.000000</td>\n",
       "      <td>2.581122e+03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.77</td>\n",
       "      <td>172.208.51.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.471786</td>\n",
       "      <td>629.141605</td>\n",
       "      <td>227</td>\n",
       "      <td>1420856.0</td>\n",
       "      <td>2043880.0</td>\n",
       "      <td>-0.594162</td>\n",
       "      <td>6259.277533</td>\n",
       "      <td>9.003877e+03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.85</td>\n",
       "      <td>151.139.47.180</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.332421</td>\n",
       "      <td>1.740996</td>\n",
       "      <td>17</td>\n",
       "      <td>177998.0</td>\n",
       "      <td>25992811.0</td>\n",
       "      <td>-24.618924</td>\n",
       "      <td>10470.470588</td>\n",
       "      <td>1.528989e+06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.77</td>\n",
       "      <td>151.139.51.188</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.694079</td>\n",
       "      <td>5.552809</td>\n",
       "      <td>17</td>\n",
       "      <td>94655.0</td>\n",
       "      <td>18805856.0</td>\n",
       "      <td>-17.844392</td>\n",
       "      <td>5567.941176</td>\n",
       "      <td>1.106227e+06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.82</td>\n",
       "      <td>151.139.51.188</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.852290</td>\n",
       "      <td>2.808766</td>\n",
       "      <td>12</td>\n",
       "      <td>868483.0</td>\n",
       "      <td>164078476.0</td>\n",
       "      <td>-155.649179</td>\n",
       "      <td>72373.583333</td>\n",
       "      <td>1.367321e+07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.77</td>\n",
       "      <td>52.137.102.105</td>\n",
       "      <td>443.0</td>\n",
       "      <td>5595.313504</td>\n",
       "      <td>4094.807482</td>\n",
       "      <td>15</td>\n",
       "      <td>26082.0</td>\n",
       "      <td>49424.0</td>\n",
       "      <td>-0.022261</td>\n",
       "      <td>1738.800000</td>\n",
       "      <td>3.294933e+03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pulling the dataframes out of the loop results, we'll have to\n",
    "# revert the column names back to the original feature name\n",
    "# which we can easily do within the list comprehension\n",
    "# Then we'll use pd.concat() to merge all of the dataframes\n",
    "# Some src/dest pairs may have been found to be outliers from multiple tests\n",
    "# so we'll drop columns added during tests as well as drop\n",
    "# duplicate rows\n",
    "\n",
    "\n",
    "normalized_df_findings = [\n",
    "    v.rename(columns={\"value\":k}) for k, v in all_findings.items()\n",
    "]\n",
    "\n",
    "all_combined = pd.concat(normalized_df_findings)\n",
    "all_combined.drop(columns=[\"sds\", \"mads\", \"iqrs\", \"anomaly_score\"], inplace=True)\n",
    "all_combined.drop_duplicates(inplace=True)\n",
    "display(HTML(all_combined.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5180c2-51c5-4e08-bfb0-f1547ca96f8e",
   "metadata": {},
   "source": [
    "#\n",
    "## While it doesn't reduce the data drastically we can apply additional filtering after the processing to drop the RFC1918, broadcast and multicast destination ip addresses as we don't expect *normal* C2 traffic to traverse to these IP spaces. \n",
    "\n",
    "##### **OBLIGATORY NOTE:** I'm aknowledging that by filtering out private IP space I could miss meaningful internal traffic that could be indicative of lateral movement, data staging/exfiltration, or even recon. Its important to keep a context based approach to the analysis process based on what we know now, what we think and what we don't know. With that in mind I know a host from the traffic sample is compromised with a somewhat commodity variant of malware, I know that after the initial compromise the infected host typically sends information to a C2 server\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69489ac1-3e4e-4ea6-ad07-f2f5ecb577e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l2/y0mbyvhn26s9h3vrd9jhk_cc0000gn/T/ipykernel_47448/961560952.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  display(HTML(all_combined[~all_combined.dest.str.contains(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>src</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>interval_average</th>\n",
       "      <th>interval_std</th>\n",
       "      <th>count</th>\n",
       "      <th>bytes_out</th>\n",
       "      <th>bytes_in</th>\n",
       "      <th>bytes_diff</th>\n",
       "      <th>out_bytes_per_session</th>\n",
       "      <th>in_bytes_per_session</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>192.168.2.82</td>\n",
       "      <td>151.101.138.172</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5782.400954</td>\n",
       "      <td>4062.185907</td>\n",
       "      <td>14</td>\n",
       "      <td>62892.0</td>\n",
       "      <td>1236375.0</td>\n",
       "      <td>-1.119121</td>\n",
       "      <td>4492.285714</td>\n",
       "      <td>8.831250e+04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.82</td>\n",
       "      <td>52.113.195.132</td>\n",
       "      <td>443.0</td>\n",
       "      <td>6032.743888</td>\n",
       "      <td>16493.810552</td>\n",
       "      <td>12</td>\n",
       "      <td>19650.0</td>\n",
       "      <td>83327.0</td>\n",
       "      <td>-0.060727</td>\n",
       "      <td>1637.500000</td>\n",
       "      <td>6.943917e+03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.19</td>\n",
       "      <td>1.1.1.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>7.316422</td>\n",
       "      <td>7.424754</td>\n",
       "      <td>11808</td>\n",
       "      <td>2030976.0</td>\n",
       "      <td>4132800.0</td>\n",
       "      <td>-2.004456</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>3.500000e+02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.77</td>\n",
       "      <td>172.208.51.75</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>71.471786</td>\n",
       "      <td>629.141605</td>\n",
       "      <td>227</td>\n",
       "      <td>1420856.0</td>\n",
       "      <td>2043880.0</td>\n",
       "      <td>-0.594162</td>\n",
       "      <td>6259.277533</td>\n",
       "      <td>9.003877e+03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.19</td>\n",
       "      <td>149.112.122.10</td>\n",
       "      <td>443.0</td>\n",
       "      <td>502.592023</td>\n",
       "      <td>342.867823</td>\n",
       "      <td>172</td>\n",
       "      <td>1381676.0</td>\n",
       "      <td>443953.0</td>\n",
       "      <td>0.894282</td>\n",
       "      <td>8033.000000</td>\n",
       "      <td>2.581122e+03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.77</td>\n",
       "      <td>172.208.51.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.471786</td>\n",
       "      <td>629.141605</td>\n",
       "      <td>227</td>\n",
       "      <td>1420856.0</td>\n",
       "      <td>2043880.0</td>\n",
       "      <td>-0.594162</td>\n",
       "      <td>6259.277533</td>\n",
       "      <td>9.003877e+03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.85</td>\n",
       "      <td>151.139.47.180</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.332421</td>\n",
       "      <td>1.740996</td>\n",
       "      <td>17</td>\n",
       "      <td>177998.0</td>\n",
       "      <td>25992811.0</td>\n",
       "      <td>-24.618924</td>\n",
       "      <td>10470.470588</td>\n",
       "      <td>1.528989e+06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.77</td>\n",
       "      <td>151.139.51.188</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.694079</td>\n",
       "      <td>5.552809</td>\n",
       "      <td>17</td>\n",
       "      <td>94655.0</td>\n",
       "      <td>18805856.0</td>\n",
       "      <td>-17.844392</td>\n",
       "      <td>5567.941176</td>\n",
       "      <td>1.106227e+06</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.82</td>\n",
       "      <td>151.139.51.188</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.852290</td>\n",
       "      <td>2.808766</td>\n",
       "      <td>12</td>\n",
       "      <td>868483.0</td>\n",
       "      <td>164078476.0</td>\n",
       "      <td>-155.649179</td>\n",
       "      <td>72373.583333</td>\n",
       "      <td>1.367321e+07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.77</td>\n",
       "      <td>52.137.102.105</td>\n",
       "      <td>443.0</td>\n",
       "      <td>5595.313504</td>\n",
       "      <td>4094.807482</td>\n",
       "      <td>15</td>\n",
       "      <td>26082.0</td>\n",
       "      <td>49424.0</td>\n",
       "      <td>-0.022261</td>\n",
       "      <td>1738.800000</td>\n",
       "      <td>3.294933e+03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(all_combined[~all_combined.dest.str.contains(\n",
    "    r\"\\b(^(127|10|255|239|224)\\.\\d{1,3}|^192\\.168|^172\\.(?:1[6-9]|2[0-9]|3[0-1]))\\.\\d{1,3}\\.\\d{1,3}\\b\"\n",
    ")].to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a933ae-532d-4b3e-a65b-46a5dfced9d2",
   "metadata": {},
   "source": [
    "## Final thoughts\n",
    "\n",
    "For the prior sample we have reduced the data down from ~44k log events to 10 combinations that are possibly malicious. After reducing the data down just doing a visual grep we can see possible src/dest combinations that we would prioritize based on the characteristics compared to the other outliers. The beaconing traffic is the \"biggest\" outlier in the group of outliers.  In this final output we see a group of connections between 192.168.2.77 and 172.208.51.75 over port 4444 (and port 0 for icmp), which standout in this grouping mainly for the non-standard port use, but from other statistical calculations that are not as obvious to the naked eye. This, is in fact the connection pair we are looking for, the XenoRat C2.\n",
    "\n",
    "Below I combined the logs from both challenges, I ended up with ~79k connection logs, 1211 session pairs and in the end the process spit out 10 pairs that stood out more than others, thats a little bit better than 90% data reduction. Of course reduction would be meaningless if the things we are looking for were lost during the reduction process, but with this final test both sets of C2 beaconing were identified as outliers.\n",
    "\n",
    "To threat hunt is to find the outliers, this is one of many possible methods to aid in making the outliers more identifiable in the sea of data. This is not a perfect method, by any means, but its promising and a simple enough process to easily incorporate into pertinent situations. As seen during the second sample the sensitivity score and max fractional anomaly setting is variable and will impact the range of outliers found. It will take some trial and error to determine what those settings look like for different datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d6d4b2-093c-43e8-8e8a-e027ac84b414",
   "metadata": {},
   "source": [
    "### Encore - combine the samples from both challenges\n",
    "\n",
    "Just out of more curiosity I combined the Zeek looks from both challenges and performed the outlier checks and *surprise* both src/dest pairs from the compromsed hosts to their respective C2 servers were idenified in the final result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24e535f5-39db-4a1f-996b-5f720470f771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Original Size': '79958', 'Aggregated Size': '1211', 'First Reduce Size': '118'} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l2/y0mbyvhn26s9h3vrd9jhk_cc0000gn/T/ipykernel_47448/387638232.py:75: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  display(HTML(all_combined[~all_combined.dest.str.contains(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>src</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>interval_average</th>\n",
       "      <th>interval_std</th>\n",
       "      <th>count</th>\n",
       "      <th>bytes_out</th>\n",
       "      <th>bytes_in</th>\n",
       "      <th>bytes_diff</th>\n",
       "      <th>out_bytes_per_session</th>\n",
       "      <th>in_bytes_per_session</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>192.168.2.19</td>\n",
       "      <td>149.112.122.10</td>\n",
       "      <td>443.0</td>\n",
       "      <td>502.592023</td>\n",
       "      <td>342.867823</td>\n",
       "      <td>172</td>\n",
       "      <td>1381676.0</td>\n",
       "      <td>443953.0</td>\n",
       "      <td>0.894282</td>\n",
       "      <td>8033.000000</td>\n",
       "      <td>2581.122093</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fe80::d4:61b7:f0bf:f504</td>\n",
       "      <td>ff02::fb</td>\n",
       "      <td>5353.0</td>\n",
       "      <td>190.622819</td>\n",
       "      <td>940.239998</td>\n",
       "      <td>454</td>\n",
       "      <td>198787.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189578</td>\n",
       "      <td>437.856828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>172.208.51.75</td>\n",
       "      <td>7707.0</td>\n",
       "      <td>6.500680</td>\n",
       "      <td>0.868396</td>\n",
       "      <td>13281</td>\n",
       "      <td>19789913.0</td>\n",
       "      <td>17996565.0</td>\n",
       "      <td>1.710270</td>\n",
       "      <td>1490.092086</td>\n",
       "      <td>1355.060989</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.19</td>\n",
       "      <td>1.1.1.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>7.316422</td>\n",
       "      <td>7.424754</td>\n",
       "      <td>11808</td>\n",
       "      <td>2030976.0</td>\n",
       "      <td>4132800.0</td>\n",
       "      <td>-2.004456</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.77</td>\n",
       "      <td>172.208.51.75</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>71.471786</td>\n",
       "      <td>629.141605</td>\n",
       "      <td>227</td>\n",
       "      <td>1420856.0</td>\n",
       "      <td>2043880.0</td>\n",
       "      <td>-0.594162</td>\n",
       "      <td>6259.277533</td>\n",
       "      <td>9003.876652</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.2.77</td>\n",
       "      <td>172.208.51.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.471786</td>\n",
       "      <td>629.141605</td>\n",
       "      <td>227</td>\n",
       "      <td>1420856.0</td>\n",
       "      <td>2043880.0</td>\n",
       "      <td>-0.594162</td>\n",
       "      <td>6259.277533</td>\n",
       "      <td>9003.876652</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.150</td>\n",
       "      <td>20.54.24.231</td>\n",
       "      <td>443.0</td>\n",
       "      <td>289.773374</td>\n",
       "      <td>378.907335</td>\n",
       "      <td>298</td>\n",
       "      <td>541451.0</td>\n",
       "      <td>1086336.0</td>\n",
       "      <td>-0.519643</td>\n",
       "      <td>1816.949664</td>\n",
       "      <td>3645.422819</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.152</td>\n",
       "      <td>20.54.24.231</td>\n",
       "      <td>443.0</td>\n",
       "      <td>291.139733</td>\n",
       "      <td>383.195294</td>\n",
       "      <td>296</td>\n",
       "      <td>540723.0</td>\n",
       "      <td>1080074.0</td>\n",
       "      <td>-0.514365</td>\n",
       "      <td>1826.766892</td>\n",
       "      <td>3648.898649</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.151</td>\n",
       "      <td>20.54.24.231</td>\n",
       "      <td>443.0</td>\n",
       "      <td>300.097482</td>\n",
       "      <td>398.506387</td>\n",
       "      <td>286</td>\n",
       "      <td>517777.0</td>\n",
       "      <td>1042743.0</td>\n",
       "      <td>-0.500647</td>\n",
       "      <td>1810.409091</td>\n",
       "      <td>3645.954545</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192.168.100.136</td>\n",
       "      <td>20.54.24.231</td>\n",
       "      <td>443.0</td>\n",
       "      <td>362.063867</td>\n",
       "      <td>417.032763</td>\n",
       "      <td>239</td>\n",
       "      <td>430524.0</td>\n",
       "      <td>865137.0</td>\n",
       "      <td>-0.414479</td>\n",
       "      <td>1801.355649</td>\n",
       "      <td>3619.820084</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conn_files = glob.glob(\"xeno*/conn.*.log*\")\n",
    "conn_files += [\"async_infection_zeek_logs/conn.log\"]\n",
    "\n",
    "dataframes = []\n",
    "for file in conn_files:\n",
    "    df = pd.read_csv(file, sep=\"\\t\", skiprows=8, names=zeek_cols[\"conn\"], low_memory=False)\n",
    "    # drop last row\n",
    "    df = df.iloc[:-1]\n",
    "    dataframes.append(df)\n",
    "df = pd.concat(dataframes)\n",
    "\n",
    "converted_timestamps = [datetime.fromtimestamp(ts) for ts in df.ts.astype(float)]\n",
    "df.insert(0, \"Time\", converted_timestamps)\n",
    "reduced = df[[\"orig_h\", \"resp_h\", \"resp_p\"]].value_counts().reset_index(name=\"pair_counts\").query(\"pair_counts > 1\")\n",
    "\n",
    "meta_list = []\n",
    "for pair in reduced.itertuples():\n",
    "    tmp_df = df[(df.orig_h == pair.orig_h) & (df.resp_h == pair.resp_h)]\n",
    "    times = tmp_df[\"Time\"].tolist()\n",
    "    intervals = make_time_interval(times)\n",
    "    count = len(intervals)\n",
    "    sum_bytes_in = tmp_df.resp_ip_bytes.sum()\n",
    "    sum_bytes_out = tmp_df.orig_ip_bytes.sum()\n",
    "    \n",
    "    meta = {\n",
    "        \"src\" : pair.orig_h,\n",
    "        \"dest\" : pair.resp_h,\n",
    "        \"dest_port\": pair.resp_p,\n",
    "        \"interval_average\" : np.mean(intervals),\n",
    "        \"interval_std\" : np.std(intervals),\n",
    "        \"count\" : len(intervals) + 1,\n",
    "        \"bytes_out\" : sum_bytes_out,\n",
    "        \"bytes_in\" : sum_bytes_in\n",
    "    }\n",
    "    meta_list.append(meta)\n",
    "\n",
    "new = pd.DataFrame(meta_list)\n",
    "\n",
    "new[\"bytes_diff\"] = (new.bytes_out - new.bytes_in) / 1024 /1024\n",
    "new[\"out_bytes_per_session\"] = new.bytes_out / new[\"count\"]\n",
    "new[\"in_bytes_per_session\"] = new.bytes_in / new[\"count\"]\n",
    "\n",
    "res_df, _, calculations = detect_univariate_statistical(new.rename(columns={\"count\":\"value\"}), 90, .10)\n",
    "first_anomalies = res_df[res_df.is_anomaly == True].rename(columns={\"value\": \"count\"})\n",
    "\n",
    "feature_names = ['interval_average','interval_std','count','bytes_out','bytes_in','bytes_diff','out_bytes_per_session','in_bytes_per_session']\n",
    "all_findings = {}\n",
    "\n",
    "\n",
    "file_meta = {\n",
    "    \"Original Size\" : f\"{len(df)}\",\n",
    "    \"Aggregated Size\" : f\"{len(new)}\",\n",
    "    \"First Reduce Size\" : f\"{len(first_anomalies)}\"\n",
    "}\n",
    "\n",
    "print(file_meta,\"\\n\")\n",
    "for feature in feature_names:\n",
    "    \n",
    "    res_df, _, calulations = detect_univariate_statistical(first_anomalies.rename(columns={feature:\"value\"})\n",
    "                                                           ,60, .05)\n",
    "    findings_df = res_df[res_df.is_anomaly == True].loc[::]\n",
    "    results_len = len(findings_df)\n",
    "    info = {'Feature': f\"{feature}\",\n",
    "             'Number_Anomalous': f\"{results_len}\"}\n",
    "    \n",
    "    all_findings[feature] = findings_df\n",
    "\n",
    "normalized_df_findings = [\n",
    "    v.rename(columns={\"value\":k}) for k, v in all_findings.items()\n",
    "]\n",
    "\n",
    "all_combined = pd.concat(normalized_df_findings)\n",
    "all_combined.drop(columns=[\"sds\", \"mads\", \"iqrs\", \"anomaly_score\"], inplace=True)\n",
    "all_combined.drop_duplicates(inplace=True)\n",
    "display(HTML(all_combined[~all_combined.dest.str.contains(\n",
    "    r\"\\b(^(127|10|255|239|224)\\.\\d{1,3}|^192\\.168|^172\\.(?:1[6-9]|2[0-9]|3[0-1]))\\.\\d{1,3}\\.\\d{1,3}\\b\"\n",
    ")].to_html(index=False)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly",
   "language": "python",
   "name": "anomaly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
